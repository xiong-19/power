#### task_struct

相关字段的详细说明： 《奔跑吧 Linux内核 p433》

`pid`: 默认最大值在，`/proc/sys/kernel/pid_max`。 tgid为其所属组的PID，getpid()返回TGID， gettid()返回PID

##### 状态说明：

TASK_RUNNING：指处于可运行状态，或者正在运行状态，或者就绪队列

TASK_INTERRUPTIBLE: 进入睡眠（可中断）(被阻塞)， 资源就位，回到TASK_RUNNING

TASK_UNINTERRUPTIBLE: 睡眠不受影响，对信号不做反映。`ps中被标记为D状态的进程`。

_TASK_STOPPED: 进程停止运行

EXIT_ZOMBLE: 进程已经消亡，但是task_struct未释放。wait()与waitpid()获取子进程消亡的原因。 

```c
#define SCHED_NORMAL		0
#define SCHED_FIFO		1
#define SCHED_RR		2
#define SCHED_BATCH		3
/* SCHED_ISO: reserved but not implemented yet */
#define SCHED_IDLE		5
#define SCHED_DEADLINE		6
```

##### 进程关系：

real_parent: 父进程，父进程不在则为`init`进程

parent: 当前父进程；children， sibling                                                                                                                                                                                                                                                   

##### current:

以前：thread_info位于栈底(32位8KB, 64位16KB)， 获取当前的SP值后, 将其对齐便可得到底部的thread_info指针，再由其task指针，即可找到task_struct

目前: thread_info放入task_struct中, 避免栈溢出污染thread_info。在内核态时，**SP_EL0未被使用到, 因此存放当前的task_struct指针, 而`task_struct的stack指向栈`。**

##### 0与1

0:idle, 1:init （1与0共享所有进程数据结构？？）。

init会执行`kernel_init()`, 调用execve()，装入init进程。如/sbin/init, /bin/init或者/bin/sh。

init变为普通进程后依据`/etc/inittab`文件内容启动一些任务，如初始化系统设置，启动一个登录对话

#### 进程创建与消亡

_do_fork(): fork(), vfork(), clone()

COW: 子进程的`页表项`与父进程相同

fork: 父子进程共享物理内存资源， 传入SIGCHLD（子进程终止后发生SIGCHLD通知父进程）

vfork: 父进程阻塞，直到子进程调用exit或者execve为止，传入CLONE_VFORK(父进程被挂起，直到子进程释放虚拟内存资源), CLONE_VM(父子进程执行相同的进程地址空间)`其可以避免复制父进程的页表项`。

clone: 可选择的继承父进程的资源。

##### 内核线程：

所有内核线程共享内核地址空间，mm为NULL。`kthread_create`: 创建内核线程处于不可运行状态，需要调用wake_up_process函数将其唤醒，并添加到就绪队列。`kthread_run`：创建便可立马运行。

##### 终止

主动：1）main返回, 运行链接自动添加的exit() 2)主动调用exit()

被动：1）进程收到不能处理的信号 2）在内核执行时产生异常 3）收到`SIGKILL`等终止信号

当进程终止时，内核释放其所有占用资源，并将信息告知父进程。1）先于父进程消亡，那么父进程调用wait（）`才真正消亡 `, `此时可以获取子进程的信息`，**（若是释放资源与进程描述符便不能达到这个目的）**2）晚于父进程， init变为子进程的父进程

<img src="http://xwf-img.oss-cn-beijing.aliyuncs.com/typora-img/0facb7d3367064e60dd14f769411a03.jpg" alt="0facb7d3367064e60dd14f769411a03" style="zoom: 12%;" />

```
do_fork
1)创建新task_strcut
2)判断是否由CLONE_VFORK标志，决定子进程是否先运行。
|--> copy_process
	|--> dup_task_struct: 分配结构，并初始化成员（内核堆栈也是在此分配，大小为16KB），_set_task_cpu: 设置运行的CPU
	|--> shed_fork: 初始化调度信息，调用各种copy_xx()。
		|--> mm_init: 其中调用了mm_alloc_pgd为子进程分配PGD
		|--> dup_mmap: 将父进程的页表复制到子进程(copy_page_range-> copy_one_pte),涉及到虚拟页面的管理。
	|--> 分配PID，并将新进程加入进程管理流程中

【进程返回问题： 在copy_thread中复制了父进程的pt_regs, x0同时修改为0，所以子进程返回值为0，返回地址被设置为ret_from_frok(thread.cpu_context成员中设置)，依据是否为内核进程，选择跳转到X19十二猴子的回调函数，或者ret_to_user】
PF_FORKNOEXEC: 进程暂时不执行
TASK_NEW: 进程不会运行， 任何信号与外部事件都不会唤醒这个进程。
```

<img src="http://xwf-img.oss-cn-beijing.aliyuncs.com/typora-img/0facb7d3367064e60dd14f769411a03.jpg" alt="0facb7d3367064e60dd14f769411a03" style="zoom: 12%;" />

<img src="http://xwf-img.oss-cn-beijing.aliyuncs.com/typora-img/6c104627b04f75de18f0958169ff121.jpg" alt="6c104627b04f75de18f0958169ff121" style="zoom:14%;" />

#### 进程调度

优先级

1）普通进程: 100 - 139

2）实时进程: 0 - 99

3）deadline： -1

```c
prio: 动态优先级
static_prio: 静态优先级，进程启动时分配
normal_prio: 基于static_prio与调度策略计算出的优先级，创建进程时会继承。
    普通进程: normal_prio = static_prio; 实时进程：依据rt_priority重新计算
rt_priority: 实时进程的优先级

此外实时调度器还使用权重表示进程的优先级：
    sched_prio_to_weight[40] 代表nice[-20~19]
```

##### 调度策略：

调度类: stop， deadline， realtime, CFS, idle。 `sched_class`,  并通过next指针串联在一起。

<img src="C:\Users\20172\Documents\WeChat Files\wxid_ue3dk2hgn28i22\FileStorage\Temp\7c0f5fb238f28e6b3237c5bd31d8b1e.jpg" alt="7c0f5fb238f28e6b3237c5bd31d8b1e" style="zoom:23%;" />

+ NORMAL：分时调度策略，所有普通的进程静态优先级都为0， 因此任何FIFO, RR都能抢占他们。`Linux没有实现此调度策略。`
+ FIFO: 一旦进程获取CPU控制权, 便一直运行下去。直到：1) 自愿放弃CPU 2) 进程终止 3）被更高优先级抢占。
+ RR：优先级相同，循环使用一个固定长度的时间片。直到：1）时间用完 + 上面3种
+ BATCH：普通进程的调度策略
+ IDLE：运行低优先级任务
+ DEADLINE：有严格时间要求的实时进程。

**用户空间程序可以使用调度策略接口函数（如sched_setscheduler）,设定用户进程调度策略**。时间片：`CFS调度器`采用权重占比的方式公平的划分CPU时间。

##### CFS

vruntime： （当nice值，不为0时，优先级高，vruntime值小于真实时间；优先级低，vruntime值大于真实时间）

+ 优先级为0-139。值越低，优先级越高。0-99为实时进程，100-139为普通进程。用户空间的nice映射到100-139。
+ `load_weight`：调度实体的权重。nice值为-20到19， 默认为0，每提升1，减少10%CPU时间，降低1，增加10%CPU时间。为了计算方便，**nice为0的权重为1024**，其他的由`sched_prio_to_weight[40]`查表获取。【nice：static_prio - MAX_RT_PRIO（100）,  load_weight->weight: 第一个数组的查表值左移10位；load_weight: 第二个数组的查表值】
+ `sched_prio_to_wmult[40]`: $inv\_weight = \frac{2^{32}}{weight}$ , 即权重被倒转。
+ $vruntime = \frac{delt\_exec * nice\_0\_weight}{weight}$, delta_exec实际的运行时间，nice_0_weight表示权重为0的权重值，weight表示该进程权重。

`sched_entity`：调度实体。描述进程作为调度实体参与调度所需的所有信息。

<img src="http://xwf-img.oss-cn-beijing.aliyuncs.com/typora-img/b2492885031cca88fff0fb8fe2a7437.jpg" alt="b2492885031cca88fff0fb8fe2a7437" style="zoom:16%;" />

`rq`：描述CPU通用就绪队列（其为`PER_CPU`），记录了一个就绪队列的全部信息。CFS就绪队列`cfs_rq`，实时进程就绪队列：`rt_rq`，与deadline：`dl_rq`， 及**就绪队列的负载权重**等信息。

进程创建关于调度器的部分（`sched_fork`）：1）将调度实体相关成员初始化为0 ，2）设置进程的状态TASK_NEW， prio = 父进程normal_prio。3）子进程的vruntime由父进程的cfs_rq相关字段计算得到(`task_fork_fair()`)。

重要函数：

`update_curr(cfs_rq)`：一个比较重要的函数。作用是依据传入的cfs_rq，更新其cfs_rq->curr的`sum_exec_runtime`，`vruntime`两个值(都是原值基础上增加)。

`place_entity(cfs_rq, sched_entity, initial)`：若initial为1，则使用cfs_rq->min_vruntime, 与sched_entity计算出一个vruntime, sched_entity的vruntime为该计算值与其原值的最大值。

`_do_fork()->wake_up_new_task()`：<font color='#FF6666'>将新进程添加到调度器中。</font> 1）设置为TASK_RUNNING 2）设置即将运行的CPU（select_task_rq）3）设置rq状态，为TASK_ON_RQ_QUEUED。4）将调度实体添加到CFS的就绪队列的红黑树中。



##### 进程调度

<b><font face="黑体" color='#FF6600'>__schedule</font>：</b>调度时机。1) 阻塞操作 2）中断返回前。系统调用返回用户空间，检查TIF_NEED_RESCHED判断。3）将被唤醒的进程不会马上调用schedule()， 而是被添加到CFS就绪队列中，并且设置TIF_NEED_RESCHED标志位。

被唤醒进程被调度时机：

+ 内核可抢占：1）唤醒发生在系统调用或者异常处理，在下一次调用preempt_enable时检查是否需要抢占调度  2）发生在硬中断处理，硬件中断返回前检查是否需要抢占当前进程。
+ 内核不可抢占：1）进程调用cond_resched()时，检查是否要发生调度。 2）主动调用schedule()

```
__schedule: 参数代表是否为抢占调度
|--> 获取当前CPU与rq
|--> schedule_debug判断是否处于automic上下文中(硬件中断，软件中断上下文)
|--> 抢占调度preempt， p->state为0。若state为非0，则说明为主动发起调度的。
|--> 主动调度，则调用deactivate_task将其移出rq
|--> 【pick_next_task】选择下一个合适的进程
```

> 进程处于运行和就绪态时，其在就绪队列中。当其睡眠时，将其移出就绪队列。处于迁移状态时，也会被移出就绪队列。

```
pick_next_task
	1）若是为CFS调度类，且CPU整个就绪队列只有CFS就绪队列的进程。调用CFS的pick_next_task
		[CFS的pick_next_task_fair函数，选择CFS就绪队列中红黑树最左边的进程。]
	2) 否者遍历整个调度类。依次调用其pick_next_task（按照优先级高低依次调用）  
	
```

<b><font color='#666699'>进程切换：</font></b>

+ 进程上下文：执行进程有关的各寄存器，内核栈，task_struct等。
+ 上文：执行过的程序指令与相关数据。下文：待执行的指令与数据。

+ 关键操作：1)保存当前进程上下文； 2）恢复被换出去进程的上下文； 3）运行被恢复进程

```
context_switch(rq, prev, next, rq_flags):  // kernel/sched/core.c
	mm = next->mm
	oldmm = prev->active_mm
	// 若mm为空，则next为内核线程，则需要设置next->active = oldmm
	swicth_to()  // 完成主要工作
	finish_task_switch:  // 1)prev的on_cpu设置为0（相当于next来处理prev尚未完成的最后一部分）
```

```
switch_mm   // 【但是调用路线上视乎没有出现这个函数】
|--> check_and_switch_context 
	// TLB分为全局：内核空间；进程独有
	// 为支持进程独有的TLB，提出了进程地址空间ID(ASID)，使每一个TLB表项都包含一个ASID。【ASID相关知识点 奔跑吧内核 p491】mm->context.id，即软件ASID{低8位为硬件ASID，其余位为计数}
	是否刷新TLB，取决于当前批次的ASID是否分配完。
	|--> cpu_switch_mm(mm->pgd, mm)
		|--> ttbr0_el1设置为 empty_zero_page
		|--> cpu_do_switch_mm进行真正的页表切换。  // 位于arch/arm64/include/asm/proc.S
			|--> 将ASID的值设置到，TTBR1_EL1, [63：48]
			|--> 将next的pgd，设置到TTBR0_EL1
```

```
switch_to(rq, prev, next, rq_flags):
	|--> __switch_to		
		|--> cpu_switch_to   // arch/arm64/kernel/entry.S
			|--> 首先利用prev的task_struct，保存各寄存器到其中。
			|--> 利用next的task_struct将保存的各寄存器值,恢复到寄存器上。
			|--> 将next的task_struct指针赋予sp_el0中。
		
```

> task_struct：使用cpu_context存储硬件上下文。(CPU寄存器的数据)
>
> switch_to是新旧进程的切换点。但是对于新建进程而言，其第一次运行的切换点在copy_thread指定的ret_from_fork中。
>
> thread_struct：存放与具体架构相关的信息。thread_struct->cpu_context。**【在进程切换时，需要将prev的X19-X28寄存器，FP，SP，PC寄存器保存到此结构中。而将next对应的寄存器恢复到寄存器中】**
>
> 为什么只有X19-X28寄存器？ 依据ARM64的调用标准，X19-X28在函数调用时需要保存到栈中（调用者与被调用者共同使用的数据），而X0-X7用于传递函数参数，剩余的通用寄存器作为临时寄存器，在进程切换过程中不需要保存。

##### 调度节拍

当时钟中断发生时, Linux调度器的scheduler_tick函数会被调用。

<img src="C:\Users\20172\Documents\WeChat Files\wxid_ue3dk2hgn28i22\FileStorage\Temp\e10d8ff8b607ee212f603a8522c40bc.jpg" alt="e10d8ff8b607ee212f603a8522c40bc" style="zoom:12%;" />

```
scheduler_stick:
|--> 首先得到当前CPU的curr， rq
|--> update_rq_clock		// 更新rq->clock, rq_clock_task
|--> curr->sched_class->task_tick  
	|--> // task_tick_fair
	|--> 【entity_tick 检查是否需要调度】
|--> cpu_load_updte_active		//更新运行队列的cpu_load[]
```

```
entity_tick
|--> update_curr  // 更新当前进程的vruntime与就绪队列的min_vruntime
|--> update_load_avg	// 更新进程的调度实体的负载与就绪队列的负载
|--> check_preempt_tick		// 检查是否需要调度
```

```
check_preempt_tick
	ideal_runtime = sched_slice()	// 依据权重在调度周期分配的实际运行时间
	若当前的实际运行时间(sum_exec_runtime - prev_sum_exec_runtime)大于ideal_runtime,则设置thread_info的TIF_NEED_RESCHED标志位。
	若小于最小值0.75ms，则不发生调度。
	若当前进程的vruntime-红黑树最左边调度实体的虚拟时间 > ideal_runtime则发生调度。
```

##### 组调度机制

`task_group`：打开CONFIG_CGROUP_SCHED与CONFID_FAIR_CROUP_SCHED

组调度的根为`root_task_group`

```c
sched_create_group(task_group parent)
	task_struct tg= alloc()
	alloc_fair_sched_group(tg, parent)
	|--> tg->cfs_rq = (cfs_rq*)[n]  // n =nr_cpu_ids
	|--> tg->se = (se *)[n]  // 两个大小为n的指针数组
	|--> tg->shares = NICE_0_LOAD
	|--> init_cfs_bandwidth(tg_cfs_bandwidth(tg)); // init_cfs_bandwidth(&tg->cfs_bandwidth)
		/*
			1. INIT_LIST_HEAD(&cfs_b->throttled_cfs_rq); 存储因为达到CPU使用限制而被节流的CFS队列
			2. 	设置单调时钟， 触发函数周期性的重置控制组的CPU时间使用量
				hrtimer_init(&cfs_b->slack_timer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);
				cfs_b->slack_timer.function = sched_cfs_slack_timer;
			3. 一些值设置，如runtime, quota
		*/
    |--> for循环每一个CPU，为每个CPU分配一个cfs_rq, sched_entity
    	|--> init_tg_cfs_entity(tg, cfs_rq, se, cpu, parent->se[cpu]) 【各数据结构如何组织】
        	struct rq *rq = cpu_rq(cpu);
    		cfs_rq->rq = rq ; cfs_rq->tg = tg
                
    		tg->cfs_rq[cpu] = cfs_rq
    		tg_se[cpu] = se
    		if(!parent)se->cfs_rq = &rq->cfs(指定CPU)
    		else se->cfs_rq = parent->my_q
    		se->my_q = cfs_rq
    		se->parent = parent
```

<img src="http://xwf-img.oss-cn-beijing.aliyuncs.com/typora-img/image-20240422152136952.png" alt="image-20240422152136952" style="zoom: 80%;" />

​	**具体来说，每个组由CPU个cfs_rq与se, 每个cfs_rq->rq 指向其所属的CPU rq->cfs_rq。对于每个实体来说，其my_q指向组的cfs_rq，而cfs_rq指向其父亲的的my_q，最终指向每CPU的cfs_rq。**

任务添加到组调度

```
cpu_cgroup_attach(cgroup_taskset):
	遍历cgroup_taskset中所有的任务，依次调用shced_move_task
	sched_move_task:
		sched_change_group(tsk, TASK_MOVE_GROUP) 将tsk移动到新的调度组
			1) 检查task是否依据关联cgroup(task->cgroups)， 然后得到tg(当前调度组)
			2) tsk->sched_class_group = tg;
			3) set_task_rq 
				1. p->se.cfs_rq = tg->cfs_rq[cpu] 2. p->se.parent = tg->se[cpu]
```

​	基本方法：1）创建tg，tg为每一个CPU创建组内调度的cfs_rq 2）组调度作为一个实体加入系统CFS就绪队列 3)进程添加到一个组后， 进程脱离系统的CFS, 而是加入了tg->cfs_rq 4）在选择下一进程时，如选中的为tg，则还需要遍历tg中的就绪队列。【代码细节没找到】



#### 负载计算

##### 理论：

+ $decay\_sum\_load = decay\_sum\_time * weight$	分别为**历史累计衰减工作负载**与**历史累计衰减时间**（可运行时间的衰减值）。
+ 量化负载：$decay\_avg\_load = \frac{decay\_sum\_runnable\_time}{decay\_sum\_period\_time}*weight$ 。就绪队列或者调度实体。weight为实体或者就绪队列的权重。
+ 将CPU就绪队列中所有进程的量化负载累加起来便可以得到CPU总负载。
+ **工作负载**：时间 * 权重
+ 对于大小核：最强的CPU的量化计算能力设置为1024。（由设备树或者BIOS提供）。rq中使用cpu_capacity_orig来描述这个计算能力。
+ $util\_avg = \frac{decay\_sum\_running\_time}{decay\_sum\_period\_time}*cpu\_capacity$        CPU利用率。时间为就绪队列或者调度实体的时间。

`sched_avg`：描述调度实体的负载信息。sched_entity与CFS就绪队列中都包含他。但是解释略有不同。

+ 进程在就绪队列中的事件，分为 1）running正在运行时间。2）runnable包含正在运行时间与等待时间。

+ **load_sum: 调度实体为decay_sum_time;调度队列为decay_sum_load**
+ load_avg: 量化负载。util_sum：统计的为正在运行状态下的累积衰减总时间。

runnable_avg_yN_inv[32]: 方便使用衰减系数，过去32ms的衰减因子。

```c
decay(val, n) // 第n个周期的衰减值。n越大衰减越多。
	return val*runnable_avg_yN_inv[n]>>32 

// n 个周期的衰减总和。 runnable_avg_yN_sum[] = 1024(y+y^1+ …… + y^n)。 1024代表一个周期1024us。

工作负载计算
// 累计衰减的计算
__update_load_sum
	sa->load_sum = sa->load_sum * y^n
    sa->load_sum += load * contrib;
	sa->runnable_load_sum = sa->runnable_load_sum * y^n
    sa->runnable_load_sum += runnable * contrib;
	sa->util_sum = sa->util_sum * y^n
    sa->util_sum += contrib * scale_cpu;
	sa->period_contib = now % 1024
量化负载
__update_load_avg
	sa->load_avg = load * (sa->load_sum/(LOAD_AVG_MAX-1024+sa->period_contrib))
    sa->runnable_load_avg = runnable(???) * (sa->runnable_load_sum/(LOAD_AVG_MAX-1024+sa->period_contrib))
```

##### PELT接口函数

```
更新实体负载信息
__update_load_avg_se()
更新CFS就绪队列信息
__update_load_avg_cfs_rq()
```

##### SMP负载均衡

```
start_kernel->setup_arch->smp_init_cpus
	// 会查询ACPI或者DTS设置cpu_possible_mask

start_kernel->rest_init->kernel_init->kernel_init_freeable->smp_prepare_cpus
	err = cpu_ops[cpu]->cpu_prepare(cpu);
	if (err)
		continue;
	set_cpu_present(cpu, true);

start_kernel->rest_init->kernel_init->kernel_init_freeable->smp_init
	遍历cpu_present_mask：调用cpu_up,然后添加到cpu_active_mask中
```

##### 调度域

+ 多核的每个核心独享L1，组成簇的核心共享L2

`sched_domain_topology_level`描述CPU的层次关系。分为SMT，MC（多核），DIE（处理器）

默认的数组default_topology

+ 调度域的标志位说明<b><font color="#66CCCC">《奔跑吧内核 p521》</font></b>

<img src="http://xwf-img.oss-cn-beijing.aliyuncs.com/typora-img/9aa6e6b8539a5d351eafdd065a715bc.jpg" alt="9aa6e6b8539a5d351eafdd065a715bc" style="zoom:15%;" />

`sched_group`：调度组。sched_domain：调度域。

```
构建过程:
start_kernel->rest_init->kernel_init->kernel_init_freeable->sched_init_smp->sched_init_domains

sched_init_domains:
	build_sched_domains()
		__visit_domain_allocation_hell // 1) 遍历默认的CPU拓扑结构default_topolopy，为每个SDTL分配sched_domain, sched_group, sched_group_capacity， per-cpu变量数据结构。2) 在每个SDTL中，为每个CPU都分配sched_domain, sched_group, sched_group_capacity。
		// 即每个cpu在每个SDTL中都有调度域核调度组
		
		// 为每个cpu创建调度域
		// SRTL的遍历是从SMT,MC,DIE递进的，所以MC可以看作SMT的父亲，其他同理。sched_domain的parent与child用于描述此关系。
		//	SDTL->data可以获取该CPU对应的sched_domain
		// sd_init(), 首先使用SDTL中的mask函数返回该SDTL下对应的兄弟CPU
		// 接着将兄弟CPU位图复制到sched_domain的span中
		
		// 调度组
		// 为每个CPU在每个SDTL中都分配调度域
		// sched_domain的groups将调度域中的所有调度组都链接到一起
		//[对于SMT，只有一个链。而对于DIE来说会将上次的所有子调度域的调度组，链成一个链表？？]
		
		♥示例图：《奔跑吧内核 p527》 sched_domain采用per-cpu的形式；而sched_group采用共享的方式。cpu之间的关系由芯片得到。
```

<img src="http://xwf-img.oss-cn-beijing.aliyuncs.com/typora-img/5341d302d28e5ec1f67273f331e6ba1.jpg" alt="5341d302d28e5ec1f67273f331e6ba1" style="zoom:15%;" />

+ 调度域添加到rq的root_domain中。【什么层级的？？】

+ **LLC调度域**：LLC最后一级高速缓存，包含LLC的最高一级调度域称为LLC调度域。由update_top_cache_domain函数查找与设置。

##### 进程唤醒

```
wake_up_process(p)
	try_to_wake_up(p, state, wake_flags)	// state唤醒进程状态；wake_flags唤醒标志位。
		select_task_rq // 返回cpu
			new_cpu = p->wake_cpu
			cpu = smp_processor_id()
			由cpu开始，自下而上的遍历调度域。快速路径: sd_flag包含SD_BALANCE_WAKE, cpu与new_cpu在同一调度域, 调度与包含SD_WAKE_AFFINE标志(唤醒进程的CPU可以运行这个进程)
			快速路径: wake_affine --> 重新计算wakeup_cpu与prev_cpu的负载情况，比较哪个唤醒进程合适,cpu + 进程负载 < newcpu， 则由cpu负责。
			若是没有合适的调度域, 则进入慢速路径:
				find_idlest_cpu查询最悠闲的CPU
```

```c
快速路径:
select_idle_sibling(p, prev, target)  // target通过计算推荐的的CPU。函数优先选择空闲CPU，没有这选择prev_cpu, 或者wakeup_cpu  
|--> available_idle_cpu(target)  
    // 通过判断当前rq->curr是否等于rq->idle, rq->nr_running, rq->wake_list是否为空。
    //若空闲则直接返回target
    
	判断两个CPU是否共享cachae，若prev为空闲则直接返回prev。
    利用task_struct->recent_used_cpu(记录了进程最近经常使用的CPU)。若recent_used_cpu满足一些条件，则返回recent_used_cpu。
	分别调用select_idle_core, select_idle_cpu, select_idle_smt 寻找是否由空闲cpu，没有则返回target_cpu
```

```c
 慢速路径:
 find_idlest_cpu(sd, p, cpu, prev_cpu, sd_flag) // cpu=wakeup_cpu; prev_cpu=current
 	若sd中的cpu不在进程允许运行的CPU位图中（p->cpus_allowed），直接返回prev_cpu
     
    从sd开始, 自上而下的遍历调度域
 		group = find_idlest_group(sd, p, cpu, sd_flag); // 遍历sd中所有调度组，比较调度组的量化负载，找出负载最小的一个调度组。
		new_cpu = find_idlest_group_cpu(group, p, cpu); // 找到调度组中负载最小的CPU
```

> 流程图见《奔跑吧内核 p539》

`wake affine特性`

+ 希望把被唤醒进程尽可能运行在wakeup_cpu上， 以便获取高速缓存命中带来的性能提升。

##### 绿色节能调度器  (EAS)

面对移动端可能出现的，突发大负载任务。希望可以快速识别，并迅速提高CPU频率，或者迁移到大核上。而PELT算法考虑到衰减信息，会推延降低CPU频率的速度。

因此Android采纳了WALT算法。

| ![249671cf4b0d041ce53a9b99c5c750d](C:\Users\20172\Documents\WeChat Files\wxid_ue3dk2hgn28i22\FileStorage\Temp\249671cf4b0d041ce53a9b99c5c750d.jpg) | ![046b2deea853e3606a1572698bcfed3](C:\Users\20172\Documents\WeChat Files\wxid_ue3dk2hgn28i22\FileStorage\Temp\046b2deea853e3606a1572698bcfed3.jpg) |
| ------------------------------------------------------------ | ------------------------------------------------------------ |

频率恒定引擎FIE：计算CPU负载时考虑CPU频率的变化。	CPU恒定引擎CIE：考虑不同CPU架构的计算能力对负载的影响，如大小核的计算能力不同。

rq的`cpu_capacity`(CPU在CFS调度类中的计算能力)  与  `cpu_capacity_orig`：cpu原有的计算能力。系统启动时，在建立调度与的拓扑结构时，会计算每个CPU的计算能力。

```
arch_scale_cpu_capacity(sd, cpu)
	return per_cpu(cpu_scale, cpu)
	
如何被设置的？
topology_parse_cpu_capacity()
	查询设备树的capacity-dmips-mhz节点, 存放于raw_capacity[]中，同时capacity_scale存放最大值。
	
topology_normalize_cpu_scale 设置每个cpu的量化计算能力
	capacity = (raw_capacity[cpu] << SCHED_CAPACITY_SHIFT) / capacity_scale
	per_cpu(cpu_scale, cpu) = capacity
```

<img src="C:\Users\20172\Documents\WeChat Files\wxid_ue3dk2hgn28i22\FileStorage\Temp\451d08c2b456cf844854d86a4808414.jpg" alt="451d08c2b456cf844854d86a4808414" style="zoom:15%;" />

`em_perf_domian`性能域：同一性能域中CPU必须拥有相同的架构。其中的table指向一个表，表的每项描述一个动态电压的调频性能操作点(DVFS OPP)。 

OPP用`em_cap_state`来描述CPU的频率与功耗之前的关系。

```c
table[i].power = power //power = dynamic_power_coefficient(能效系数？)*freq * mv^2(电压)
tbale[i].frequency = freq
tbale[i].cost = (max_frequency*table[i].power)/ tbale[i].frequency  
```

> $current\_capacity = scale\_cpu * \frac{freq}{max\_freq}$
>
> $cpu\_energy = cost* \frac{cpu\_util}{scale\_cpu}$    // CPU功耗
>
> 对于进程的实际算了：p->se.avg.util_avg



开启CONFIG_ENERGY_MODEL配置才能使用绿色节能调度器。

+ 能够单独设置频率核电压的功能模块称为电源域。这些频率和电压组成的点称为OPP。对于电源域而言可能由多个OPP组成，形成OPP表

OPP接口函数：使用需要开启:`CONFIG_PM_OPP`。

```c
cpufreq_init  // 完成对OPP表和能效模型的初始化
    cpu_dev = get_cpu_device(policy->cpu);  // per_cpu(cpu_sys_devices, cpu);
	dev_pm_opp_of_cpumask_add_table(policy->cpus)  // 初始化opp表，通过查询设备树固件，将相关值填入系统的OPP表中
    ret = dev_pm_opp_get_opp_count(cpu_dev);  // 获取OPP表的项数，并检查是否创建不成功。
	ret = dev_pm_opp_init_cpufreq_table(cpu_dev, &freq_table);  // 创建CPUfreq表
	dev_pm_opp_of_register_em(cpus)  //注册能效模型  【4.19上没有找到这个函数】【5.1后合并到社区】
    |--> 将CPU注册到能效模型子系统中
    |--> 填充回调函数；调用em_register_perf_domain向能效模型子系统注册。
        详见【奔跑吧linux内核 p558】【4.19上无相关代码】
em_register_perf_domain(span, nr_states, cb) // 将参数的span中的CPU组成一个性能域
	首先检查CPU的计算能力是否不一致。
    em_create_pd: 创建性能域。 // 将每个OPP项放入pd->table中。
    将pd，存放到每个CPU的Per-CPU的em_data中。
```

<img src="http://xwf-img.oss-cn-beijing.aliyuncs.com/typora-img/3c2deeb37690a2f6c4ea219ba81eaf6.jpg" alt="3c2deeb37690a2f6c4ea219ba81eaf6" style="zoom: 15%;" />

<b><font color='#CC9999'>对于绿色节能调度器而言唤醒进程时的处理</font></b>

```
wake_up_process -> try_to_wake_up -> select_task_rq_fair
select_task_rq_fair:
	首先判断当前系统是否支持绿色节能调度器. 全局变量sched_energy_present控制。
	find_energy_efficient_cpu查找一个能效比最优的CPU。【_get_cpu_power函数中计算得到，并设置到em_cap_state】
		读取当前CPU对应的sd_asym_cpucapacity调度域（具有共享缓冲的调度域）。从该调度域往上查找一个合适的调度域（需包含当前CPU, 与prev_cpu）。
		具体流程图见【p564】
```

+ overutilized条件判断。若当前没有触发overutilized的”Tipping Point“条件。则绿色节能调度器会禁止启动负载均衡。主要是判断当前CPU的实际算力需求是否超过CPU的额定算力的80%。超过了则触发overutilized, 设置标志位SG_OVERUTILIZED,  设置到rd->overutilized中。
+ 除了负载均衡会判断overutilized外，每次时钟节拍处理器也会做出这样的判断。`scheduler_tick -> task_tick_fair -> update_overutilized_status`



##### 动态调频

CPUfreq通过内核接口函数采样CPU的空闲时间和活跃时间完成调压调频。

schedutil: 充分利用调度器提供的CPU Utilization作为CPU调频依据的驱动程序。需要内核开启`CONFIG_CPU_FREQ_GOV_SCHEDUTIL`

```c
sugov_start  //为每个CPU建立schedutil回调函数 
    
// 思路：创建了一个新的数据结构update_util_data（存放回调函数）。并创建per-cpu此数据结构的实例，cpufreq_updata_util_data (静态的？ 【P572】)

// 调度器中实现接口函数cpufreq_update_util， 以per-cpu变量为桥梁访问func指向的回调函数。
```

| ![3c12b106b211b658cbd27cc92901dc9](http://xwf-img.oss-cn-beijing.aliyuncs.com/typora-img/3c12b106b211b658cbd27cc92901dc9.jpg) | ![6c0412d10191f1a7b69a6c8dd8a2f8a](http://xwf-img.oss-cn-beijing.aliyuncs.com/typora-img/6c0412d10191f1a7b69a6c8dd8a2f8a.jpg) |
| ------------------------------------------------------------ | ------------------------------------------------------------ |

##### 实时调度

<img src="C:\Users\20172\Documents\WeChat Files\wxid_ue3dk2hgn28i22\FileStorage\Temp\e0a65d16d11cab820f57b7e7e6f2cd2.jpg" alt="e0a65d16d11cab820f57b7e7e6f2cd2" style="zoom:20%;" />

如果内核不支持抢占，那么要在系统调用，异常处理和中断处理完成返回用户空间前才能进行调度。会使得内核调度的延迟很大。在支持的情况下，若是唤醒动作发生在系统调用或者异常处理上下文中，那么下一次调用`preemt_enable`时会检查是否需要抢占调度。preemt_enable会主动调用`__preempt_schedule`。

thread_info的`preempt_count`为0时，表示内核可以抢占。大于1时，表示禁止抢占。`preempt_disable`时+1；`preempt_enable`时-1。

+ 中断返回前也会检查是否要抢占当前进程(中断处理返回$\neq$用户空间返回)

<b><font color='#CC9999'>ftrace: 用于检查系统调用哪些地方有较大的调度延迟。</font></b>

<b><font color='#CC9999'>latencytop: 在内核上下文切换时记录被切换进程的内核栈，然后匹配内核栈，判断导致上下文切换的原因。</font></b>



#####  负载均衡详解

 负载均衡在软中断中注册

``` c
start_kernel -> sched_init -> init_sched_fair_class
init_sched_fair_class:
	open_softirq(SCHED_SOFTIRQ, run_rebalance_domains)

run_rebanlance_domains:
/*
1) 若当前cpu有no_hz: 则对其余每一个cpu执行rebalance_domains(cpu_rq(balance_cpu))(有一个时间限制) 
2） rebalance_domains(this_rq(), idle);
*/      
        
rebalance_domains:
	循环遍历当前CPU从下而上的调度域。【最底层调度域】然后调用load_balance()

load_balance(cpu, rq, sd)
	should_we_balance
		1) sd->groups, 调度组。遍历调度组，找到空闲的CPU，没有则返回第一个CPU 2) 若选择出的CPU为当前CPU则，做负载均衡。
	
	find_busiest_group
		// sd_lb_stats, sg_lb_stats。 调度域或者调度组的相关信息。
		update_sd_lb_stats 计算当前调度域的总负载，总容量以及各组的单独负载。并将最繁忙的组的统计信息放入sg_lb_stats busiest中(比较各调度组量化负载的平均值[avg_load]来寻找对繁忙的调度组)。
			|--> update_sg_lb_stats：遍历调度组的所有CPU，调用target_load或者soure_load计算负载。并返回调度组的状态。
		计算整个调度域的平均负载。
		是否不平衡？ 1) busiest被标记为group_imbalanced 2) 本地调度组的平均负载大于最繁忙调度组的，空闲CPU小于，本地平均量化负载大于，都不要进行负载均衡【本地调度组，比最忙的组还要繁忙】
		
		calculate_imbalance 计算需要迁移多少负载才能达到平衡。min(最繁忙组avg_load-调度域avg_load, 调度域avg_load - local avg_load)
		
	
	find_busiest_queue
		在最繁忙的调度组中，找到最繁忙的就绪队列。
		//遍历调度组中所有的CPU，通过就绪队列的runnable_load_avg与cpu_capacity的乘积进行比较。
	
	detach_tasks: 找到进行队列中哪些进程可以被迁出。
		遍历就绪队列所有进程。
		can_migrate_task判断哪些进程可以迁移。不能的原因：1)cpu_allowed限制 2) 进程正在运行 3) cache_hot的原因。递减env->imbalance。
		detach_task：进程退出就绪队列，p->on_rq = TASK_ON_RQ_MIGRATING。迁移进程加入env->tasks中。
		
	attach_tasks:将分离进程重新添加进就绪队列。迁移到env->dst_rq = this_rq
```

<img src="http://xwf-img.oss-cn-beijing.aliyuncs.com/typora-img/723cd2d30252e64b4980f495c7667f3.jpg" alt="723cd2d30252e64b4980f495c7667f3" style="zoom:25%;" />





#### 进程迁移详细分析

```c
struct migration_arg arg = { p, cpu };
stop_one_cpu(task_cpu(p), migration_cpu_stop, &arg);
/*
	1. 由进程当前cpu，执行migration_cpu_stop
	
*/
stop_one_cpu(int cpu, cpu_stop_fn_t fn, void* arg){
    struct cpu_stop_done done; 
    // done->nr_todo=1; done->completion->done=0;init_waitqueue_head(&done->completion->wait);
    cpu_stop_queue_work(cpu, &work);
    cond_resched();
	wait_for_completion(&done.completion);
    /* 循环以下：
    	1. 当前进程加入x->wait中, 设置当前进程的状态为TASK_UNINTERRUPTIBLE
    	2. 循环：直到 x->done or timeout
     		2.1 调用schedule_timeout(timeout)
    */ 
}

// 唤醒stopper来运行函数
static bool cpu_stop_queue_work(unsigned int cpu, struct cpu_stop_work *work){
    struct cpu_stopper *stopper = &per_cpu(cpu_stopper, cpu);
	DEFINE_WAKE_Q(wakeq);

	enabled = stopper->enabled;
	if (enabled)
		__cpu_stop_queue_work(stopper, work, &wakeq);
    	/*
    		1. 将work->list挂入stopper->works 2. 将stopper->thread->wake_q加入wakeq中
    	*/
	else if (work->done)
		cpu_stop_signal_done(work->done);

	wake_up_q(&wakeq);
    // 1.task = container_of(node, struct task_struct, wake_q); 2.wake_up_process(task);
}

static int migration_cpu_stop(void *data){
    rq = this_rq();
    /*
    	1.	rq与p加锁
 		2. p->rq == rq : 进程原rq是否为当前cpu的rq   --> 是否进程所在的cpu是否为当前cpu
        2.1 rq = __migrate_task(rq, &rf, p, arg->dest_cpu);  注：同时其需要在原rq队列上
        2.2 p->wake_cpu = arg->dest_cpu;
        3.	rq与p解锁
    */
}

__migrate_task:
|--> move_queued_task(struct rq *rq, struct task_struct *p, int new_cpu){
    	dequeue_task(rq, p, DEQUEUE_NOCLOCK);
        set_task_cpu(p, new_cpu);
    	/*
    	1. migrate_task_rq_fair(p. new_cpu)
    		p->se.nr_migrations++;
    	2.
    		struct task_group *tg = task_group(p);
    		p->se.cfs_rq = tg->cfs_rq[cpu];
			p->se.parent = tg->se[cpu];
        */
    
        rq_unlock(rq, rf);
        rq = cpu_rq(new_cpu);
        rq_lock(rq, rf);  // 解锁位于 migration_cpu_stop中
        enqueue_task(rq, p, 0);
        p->on_rq = TASK_ON_RQ_QUEUED;
}

/**********(1：dequeue)**********/

struct sched_entity {
	struct rb_node			run_node;
	struct list_head		group_node;
	unsigned int			on_rq;
	u64				nr_migrations;
#ifdef CONFIG_FAIR_GROUP_SCHED
	int				depth;
	struct sched_entity		*parent;
	/* rq on which this entity is (to be) queued: */
	struct cfs_rq			*cfs_rq;
	/* rq "owned" by this entity/group: */
	struct cfs_rq			*my_q;
};

#ifdef CONFIG_FAIR_GROUP_SCHED
#define for_each_sched_entity(se) \
		for (; se; se = se->parent)
#else
#define for_each_sched_entity(se) \
		for (; se; se = NULL)


// 在nr_running减少后被调用； 将task从rbtree中移除，并且更新fair scheduling states
// flgas: DEQUEUE_NOCLOCK
static void dequeue_task_fair(struct rq *rq, struct task_struct *p, int flags){
    struct sched_entity *se = &p->se;
	int task_sleep = flags & DEQUEUE_SLEEP;
    for_each_sched_entity(se) {
        cfs_rq = cfs_rq_of(se);   // cfs_rq != rq->cfs, 有这种可能性吗？？？
        // 针对是否有组调度：1. cfs_r = se->cfs； 2.  cfs_rq = task_rq(tak_of(se))->cfs
		dequeue_entity(cfs_rq, se, flags);
        cfs_rq->h_nr_running--;
    }
    if (!se)
        sub_nr_running(rq, 1);
    hrtick_update(rq); // 设置了一个高精时钟 
}
void dequeue_entity(struct cfs_rq *cfs_rq, struct sched_entity *se, int flags){
    
    update_curr(cfs_rq); // 更新cfs_rq->curr的runtime统计数据
    /*
	 * When dequeuing a sched_entity, we must:
	 *   - Update loads to have both entity and cfs_rq synced with now.
	 *   - Substract its load from the cfs_rq->runnable_avg.
	 *   - Substract its previous weight from cfs_rq->load.weight.
	 *   - For group entity, update its weight to reflect the new share
	 *     of its group cfs_rq.
	 */
    if (se != cfs_rq->curr)
		__dequeue_entity(cfs_rq, se);
    // rb_erase_cached(&se->run_node, &cfs_rq->tasks_timeline);  从红黑树中删除指定节点。
    se->on_rq = 0;
    update_cfs_group(se); 
    /*
    	1. struct cfs_rq *gcfs_rq = group_cfs_rq(se); //se->my_q
    */
}


/**********(2：enqueue)**********/
// 在nr_running上升前调用； 更新调度状态，将task加入rbtree
enqueue_task
|--> static void enqueue_task_fair(struct rq *rq, struct task_struct *p, int flags){
    	util_est_enqueue(&rq->cfs, p); // 更新cfs队列的利用率
    	struct sched_entity *se = &p->se;
    	for_each_sched_entity(se) {
            if (se->on_rq)
                break;
            cfs_rq = cfs_rq_of(se);
            enqueue_entity(cfs_rq, se, flags);
            if (cfs_rq_throttled(cfs_rq))
                break;
            cfs_rq->h_nr_running++;
            flags = ENQUEUE_WAKEUP;
		}
    
	}
enqueue_entity(){
    // 更新cfs_rq的各种记录数据
    if (!curr)
		__enqueue_entity(cfs_rq, se);
	se->on_rq = 1;
}
static void __enqueue_entity(struct cfs_rq *cfs_rq, struct sched_entity *se)
{
	struct rb_node **link = &cfs_rq->tasks_timeline.rb_root.rb_node;
	struct rb_node *parent = NULL;
	struct sched_entity *entry;
	bool leftmost = true;
	/*
	 * Find the right place in the rbtree:
	 */
	while (*link) {
		parent = *link;
		entry = rb_entry(parent, struct sched_entity, run_node);
		if (entity_before(se, entry)) {
			link = &parent->rb_left;
		} else {
			link = &parent->rb_right;
			leftmost = false;
		}
	}
	rb_link_node(&se->run_node, parent, link); // 将新节点链接到父节点上，更新父节点的子节点
	rb_insert_color_cached(&se->run_node,
			       &cfs_rq->tasks_timeline, leftmost); // 完成着色与平衡调整
}

```

#### context_switch详细分析

```c
prepare_task_switch  // 正确记录状态变化
    kcov_prepare_switch  // 设置task_struct->kcov_mode
    //kcov（Kernel Coverage）用于监控内核代码的执行路径。它可以帮助开发者检测哪些代码路径被执行，通常用于测试和调试目的。
   // 当某个进程或线程启用 kcov 时，内核会为其分配一个覆盖率缓冲区，并初始化相关状态。
   // 覆盖率收集：在 kcov 启用后，内核会在代码执行路径的关键点插入钩子函数，将执行路径记录到覆盖率缓冲区中。
   // 数据导出：测试完成后，可以将覆盖率数据从内核空间导出到用户空间进行分析。
    
	sched_info_switch // 1.记录换出换入进程的task_struct->sched_info的信息（运行时间相关）（开启相应配置的情况下才会启用）
    perf_event_task_sched_out  // 1.若是sw事件的switch事件开启，则获取perf需要的几个寄存器值。2.事件计数加1，与溢出处理  （主要是perf的switch事件处理） 3.若perf的sched事件开启，清除与当前任务相关的性能事件。 具体：若有sched回调函数则调用，若需要则输出switch事件（可能），遍历每一个任务上下文（其实只有两个，硬件上下文与软件上下文），将该上下文从其所属的perf_cpu_context中去除
    rseq_preempt  // 设置task_struct的一些标志位。重启序列是一段代码，在其执行期间，如果发生了中断（如信号、抢占、上下文切换等），可以安全地重新执行。
    fire_sched_out_preempt_notifiers // 若是发生了抢占，则遍历当前所有任务的抢占通知器，调用相关的sched_out回调函数。允许在任务（进程或线程）被抢占之前和之后，通知相关的子系统或模块进行特定操作。
    prepare_task  // 多核的情况下,设置next的on_cpu为1
    prepare_arch_switch // 依据架构，其实为空
    
// mm处理
// 1.若下一个为内核进程，则设置next->active_mm=prev->active, 若启用    CONFIG_ARM64_SW_TTBR0_PAN则，设置task_thread_info(tsk)->ttbr0指向零页，防止内核空间访问用户空间
//2. 若不是，switch_mm,  设置task_thread_info(tsk)->ttbr0 = mm->pgd | ASID(mm);   
prepare_lock_switch   // 将rq的锁给next进程
swtich_to(prev, next, prev);   [***]
finish_task_switch(prev);	   [***]	
```

````c
switch_to
|--> __switch_to   
fpsimd_thread_switch  //  1.将当前的FPSIMD或者SVE保存到内存中(是否保存取决于prev是否有TIF_FOREIGN_FPSTATE标志)。若是进程有TIF_SVE标志，则判断向量长度是否匹配，不匹配则杀死当前进程。匹配则保存sve寄存器保存到内存中（current->thread中）
 // 若SVE未启动则，保存FPSIMD到内存中  （__this_cpu_read(fpsimd_last_state.st)中）
// 2.若是FPSIMD需要重新加载则next标志设置为TIF_FOREIGN_FPSTATE
tls_thread_switch  // 线程本地存储TLS，允许每个线程拥有自己的独立变量。ARM下通过系统寄存器实现。
// tpidr_el0: 用户空间TLS寄存器。在任务切换时会被更新为当前线程TLS值
// tpidrro_el0：只读 TLS 寄存器，通常用于兼容模式或者特殊用途。
// 在线程创建时，为每个线程分配一块内存用于存储 TLS 数据；通过访问这些寄存器来获取和修改自己的 TLS 数据   
// 1.将当前的tpidr_el0寄存器值写入当前进程的task_struct 2.若为兼容线程（32位应用在64位上运行），则设置tpidrro_el0为next的值, 若内核与用户不共享地址空间，则tpidrro_el0设置为0，设置tpidr_el0为next的值
hw_breakpoint_thread_switch //  依据前后进程的debug_info的断点状态breakpoints、watchpoints,来更新对应的系统寄存器   
contextidr_thread_switch // 将next的pid写入contextidr_el1。 contextidr_el1用于识别当前执行的上下文，对于调试性能监控具有一定作用。
entry_task_switch  // 将next写入PER_CPU变量__entry_task中

uao_thread_switch  //UAO（User Access Override）是ARMv8.2引入的一项特性，允许内核代码在访问用户空间内存时使用更简单的访问模式。使用 PSTATE 寄存器中的 UAO 位来控制访问行为。
// 依据next的addr_limit决定是否启用UAO    
ssbs_thread_switch // 推测性存储绕过（Speculative Store Bypass, SSB）是一种 CPU 优化技术。可能在某些情况下导致安全漏洞（例如 Spectre v4）。为了缓解这一风险，ARM 处理器引入了 SSBS 机制。
// 存储绕过：当处理器读取一个变量时，如果它预测该变量的值没有被修改，可能会直接使用缓存中的旧值。这种预测若不准确可能导致信息泄露。    
// PSTATE 寄存器中有一个 SSBS 位，设置 SSBS 位可以禁用 SSB，从而防止可能的安全漏洞
// 1.依据next的状态设置pstate的对应位    
cpu_switch_to  // 切换通用寄存器    
````

````c
finish_task_switche：
vtime_task_switch // 
perf_event_task_sched_in // 与前面perf_event_task_sched_out相近   

finish_task(prev) // 设置prev->on_cpu=0    
finish_lock_switch // rq解锁
kcov_finish_switch  // 设置current->kcov_mode    
fire_sched_in_preempt_notifiers(current);  // 调用对应的sched_in回调函数

//若是切换前的进程为TASK_DEAD，则前用对应调度类的task_dead函数，并清空对应的kprobe，栈，task_struct
tick_nohz_task_switch //任务切换时重新评估是否需要重新启动时钟中断，依据current->tick_dep_mask和current->signal->tick_dep_mask判断  是否具有这些依赖性。需要，会创建一个新的 audit_context 实例
````

```c
do_fork:
//确定是否被traced

copy_process
// 先检查是否存在不合适的clone_flags搭配。    
// 1.分配task_struct,分配stack, 初始化一些标准位；初始的usage=2,一个为父进程，一个为自己；thread_info完全复制父进程的；标记内核栈的内存的地址属于同一个区域控制组；kcov单独分配设置的；2。初始画RCU，children,sibling等成员变量，初始化task->pending;初始化task中的各种时间
//3.timer_slack_ns定时器的松弛状态，允许松弛触发定时器，使得可以减小cpu唤醒次数，节能
//[*] task->ioac I/O accounting记录I/O活动统计信息。帮助分析I/O密集应用。  
//[*] task->audit_context 审计（Audit）子系统,用于记录和查看系统事件。系统调用、文件访问、网络操作等。当进程执行一个系统调用时，审计子系统会检查当前进程是否需要被审计。
//[*] io_context 帮助内核优化 I/O 请求的调度和合并，以提高磁盘和存储设备的利用率。I/O 调度器使用 io_context 信息来优化 I/O 请求的处理顺序和优先级。
//4.初始化task的timer    
    
// delayacct（delay accounting）用于追踪和记录进程在不同状态下的时间延迟，记录如I/O，CPU，内存等的延迟，用户空间可以通过proc或者cgroup文件系统获取这些延迟数据   
    
//  1.完成调度相关的设置优先级，调度类等。2.初始化perf，没有共用。  
// 3.是否撤销型号量undo_list    4. 复制files, fs
// 5.复制sighand结构体， 复制signal结构体(根据是否为CLONE_THREAD来决定是否创建新的)  
// 6.复制mm，命名空间，io
// [*]fpsimd共享否？    
// 7.copy_thread 复制栈，并设置reg[0]为0, 设置新进程的pc为ret_from_fork   
// 8.perf_event_fork 输出一些信息
// 9.uprobe复制；OOM Killer：当系统内存不足时，OOM Killer 会选择一个"最不重要"的进程进行终止，以释放内存。选择过程依赖于进程的 oom_score_adj，值越高，进程越有可能被终止。    
    
//唤醒新进程，根据需要父进程是否等待子进程死去    
```

##### TTBR切换详细内容

```shell
switch_mm_irqs_off:
0. 判断新进程的ASID是否是否需要更新,active_asids是否被设置，不满足可能刷新tlb
1. 将ttbr0_el1设置为零页
2. 将ttbr1_el1的ASID设置为当前进程的ASID， 当前进程的pgd设置到ttbr0_el1(注意若是有SW_TTBR0_PAN设置，则ASID也需要设置到ttbr0_el1上)
3. 若是配置了SW_TTBR0_el1_PAN, 将pgd|ASID写入task_thread_info(tsk)->ttbr0 （没有配置硬件PAN的情况下）

# kernel_exit
|===> 以下都为配置了软件PAN而没有物理PAN的情况
获取thread_info中的ttbr0_el1的值, 将这个值的ASID设置到ttbr1_el1寄存器中，同时写入ttbr0_el1寄存器
# kernek_entry
将当前的ttbr1_el1寄存器的ASID去除，并将ttbr1_el1减去的一个固定值写入ttbr0_el1
```



#### try_to_wake_up

```c
try_to_wake_up:
WRITE_ONCE(p->__state, TASK_WAKING);
cpu = select_task_rq(p, p->wake_cpu, wake_flags | WF_TTWU); 选择合适CPU
set_task_cpu(p, cpu)：  
p->sched_class->migrate_task_rq(p, new_cpu); 更新p的虚拟时间，更新负载均衡值
__set_task_cpu; 改变进程的cfs_rq与父调度实体（若是发生了跨CPU或者调度组）,设置p->cpu等变量
	struct task_group *tg = task_group(p);
    p->se.cfs_rq = tg->cfs_rq[cpu];
	p->se.parent = tg->se[cpu];
	p->cpu = cpu
    
ttwu_queue:

ttwu_do_activate：
    activate_task：将进程插入队列（更新cfs队列的状态，并插入到tb树中）
    	cfs_rq = cfs_rq_of(se);
		enqueue_entity(cfs_rq, se, flags);

ttwu_do_wakeup：标记进程可执行，并发生抢占
    WRITE_ONCE(p->__state, TASK_RUNNING);    
    check_preempt_curr：
    check_preempt_wakeup(); 必要的情况下抢占当前的进程;
0. 不发生抢占:调度实体与当前相同；下一个实体被节流
    1. 发生抢占：当前为idle，下一个不为；wakeip_preempt_entity判断为真（即从虚拟时间看确实需要抢占）。
    2. 设置抢占标志位，若是唤醒其他核上的进程，则发起核间中断   

```

```c
static struct rq *move_queued_task(struct rq *rq, struct rq_flags *rf,
				   struct task_struct *p, int new_cpu)
{
	lockdep_assert_rq_held(rq);

	deactivate_task(rq, p, DEQUEUE_NOCLOCK);
	set_task_cpu(p, new_cpu);
	rq_unlock(rq, rf);

	rq = cpu_rq(new_cpu);

	rq_lock(rq, rf);
	BUG_ON(task_cpu(p) != new_cpu);
	activate_task(rq, p, 0);
	check_preempt_curr(rq, p, 0);

	return rq;
}

aarch64-linux-gnu-objdump -S fair.o > /tmp/fair.txt
e2fsck -y ubuntu.img
```

#### 调度实体在cfs_rq上的插入，消去的变化

对于一个睡眠的进程：

+ 首先在wake_up时，便会将其se插入选择的CPU的cfs_rq中；on_rq = 1
+ 在其被选中后（pick_next_task_fair中）将被调度。在pick_next_task_fair中(on_rq==1)将其移出cfs_rq

对于一个正在运行的进程:

+ 若是主动睡眠
  + 那么将调用deactivate_task设置on_rq=0。
  + 在pick_next_task_fair中，由于on_rq==0,则不做处理

+ 若是自然被切换
  + 那么不会调用deactivate_task并且on_rq=1
  + 在pick_next_task_fair中，由于on_rq==1,则不重新插回cfs_rq



#### 工具： 

<b><font color='#CC9999'>[1] ftrace: 用于检查系统调用哪些地方有较大的调度延迟。</font></b>

<b><font color='#CC9999'>[2] latencytop: 在内核上下文切换时记录被切换进程的内核栈，然后匹配内核栈，判断导致上下文切换的原因。</font></b>

#### 索引：

<font color='red'>task_struct关于调度相关字段的详细说明： 《奔跑吧 Linux内核 p433》</font>

<font color='ef0000'>常见的CLONE_flages 《奔跑吧内核 p447》</font>

<font color='ef0000'>task_struct与调度器相关的成员 《奔跑吧内核 p474》</font>

<font color='ef0000'>rq成员说明 《奔跑吧内核 p476》</font>

<font color='ef0000'>ASID相关知识点 《奔跑吧内核 p491》</font>

#### 问题：

1） namespace

2）内核分配的空间是直接分配到位的吗。如，内核堆栈的分配。

3）sched_entity实体是如何组织的

<b>进程体积的大小视乎没有被考虑到负载均衡中，nice中有考虑吗？</b>

系统调用时发生的什么页表那些，切换的时候，切换关于task_struct关键的内容时，堆栈发生的变化。
