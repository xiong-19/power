#### 内核启动

+ `__create_page_tables`

```
(1) 清空init_pg_dir到init_pg_end
(2) 将物理地址的__idmap_text_start到__idmap_text_end区域映射到对应的物理地址（以此可以发生函数跳转，相对跳转）在idmap_pg_dir中。
(3) 将_start与_end的虚拟地址映射到其对应的虚拟地址地址。 
	va = pa+KIMAGE_VADDR
建立两个映射的原因开启MMU时，PC为一个很小的值，采用ttbr0_el1(idmap_pg_dir); ttbr1_el1(init_pg_dir)	
注意：此处为2MB的块映射。

开启mmu：
	bl	__enable_mmu    // 分别设置ttbr0_el1; ttbr1_el1, 设置sctlr_el1寄存器
	ldr	x8, =__primary_switched
	adrp	x0, __PHYS_OFFSET
	blr	x8
```

+ `__primary_switched`

```
(1) 将init写入sp_el0, 并设置init的栈
(2) 写vectors到vbar_el1
(3) 设备树保存到__fdt_pointer中
(4) 内核镜像与物理地址的偏移写入kimage_voffset
```

##### 内存管理

```
(1) NUMA: 内存节点数据结构pglist_data * [];管理各个内存节点; 内存节点由ACPI枚举获取

内存管理区：ZONE_NORMAL用于线形映射内存； ZONE_DMA:ISA设备的DMA操作，arm无; ZONE_HGHMEM不能线形映射到内核空间

mem_map[]; 管理所有的物理页面

(2) 内存块在memblock_add添加到了memblock子系统中

(3) 初始化内核页表paging_init
	1. 将内核映像各段分别映射   =》 vmalloc
	2. 物理最低点到镜像开始处； 镜像开始到结束处；内核镜像结束到物理内存结束 =》 映射到线形映射区
注意：此处为页映射（也可能为1G的块映射）

(4) 一个pglist_data可能包含多个zone; zone->free_area[MAX_ORDER]伙伴系统结构体，每个变量有MIGRATE_TYPES个链表。
如：不可移动，可移动，不可回收
 
(5) 伙伴系统初始化：遍历所有内存块，找到对应的起始地址与结束地址，然后依次添加到不同的链表中
```

##### 分配内存

+ 内存管理结构与伙伴系统

```
alloc_pages: 仅能分配2^n大小； 

掩码gfp_mask：
	[1] 内存管理区 0:4 [2] 移动 [3] 水位 [4] 页面回收 [5] 行为(如0页，远端分配)

alloc_page:
	(1) 确定首选zone   (2) 在zone的空闲链表中分配  （3） 分配不成功则慢速路径
	
pglist_data包含两个zonelist, 本地与NUMA远端， 其中zonelist指向一个zoneref结构体数组，结构体两个成员变量一个指向zone，一个为zone的idx，越位于数组前约被优先选中 (还取决于gfp_mask)

（2）	从推荐的zone，开始遍历所有的zone
外碎片化：有足够的内存，但是不能分配出足够的内存。
	1. 当满足order要求与水位要求
	2. 不满足需求则从下一个zone，或者进行内存回收操作

rmqueue 从伙伴系统中分配内存： per-cpu变量per_cpu_pages单链表暂时存储小部分单页面，用于分配order=0;
先从相同类型的链表中找(回逐渐提升oder)，若是没有再从其他类型链表借用


free_page:
	1. 单页面放回pcp链表
	2. 将页面添加如伙伴系统的空闲链表，并且释放时会检测是否与相邻空闲内存合并
```

+ slab => kmalloc物理地址连续

```
slab: 对于NUMA有多个slab节点, slab节点的链表挂有多个slab分配块
	1. 创建slab描述符 kmem_cache; 其array_cache结构体即可以描述共享缓冲池也可以描述本地缓冲池(对象地址)
	2. 初始化kmem_cache的各成员变量值如一个slab分配器具有多少个页面，包含多少个对象。添加入slab_caches全局变量

slab分配器: [着色区, n*obj, freelist]  freelist每个成员变量占一个字节,代表一个obj;
依据freelist的大小与slab对象的大小比较结果, 剩余空间大小决定freelist的位置
kmem_cache_node slab节点, 三个链表

slab对象分配: kmem_cache_alloc
	1. 先看本地对象池  (但是第一次分配时是没有的， 3个链表也是空的。所以会分配一个slab)
	2. 看共享池，贡献池有则从贡献池拿
	3. 查看slab节点,从slab节点拿取多个对象到本地池
	4. slab也没有，则分配slab分配器，将slab分配器其放入合适的slab节点的合适队列
slab对象释放: kmem_cache_free
	1. 当本地贡献池的空闲对象大于阈值时会触发回收动作
		1.1 看贡献池空闲对象是否达到阈值, 没有则复制到共享池, 达到则释放共享对象
		1.2 slab没有活跃对象则将其添加入free链表，有则添加入部分free链表  （活跃对象迁移到了池中）
		1.3 若是slab节点的空闲对象超过阈值则销毁slab分配器
	2. 将对象放回本地池
注意：
(1) slab调用伙伴系统分配页面的， 页面被标记PG_slab
(2) 回收问题：一、是在主动释放对象时检测。二、是定时器，扫描所有slab描述符号
```

+ vmalloc: 虚拟地址连续而物理地址不连续。从`VMALLOC_START, VMALLOC_END`分配

```
(1) 大小页面对齐
(2) 分配一个vm_struct
(3) 在vmalloc区寻找一个合适的空间
注意： valloc区,存在一个vmap_area_root红黑树, 管理vmalloc区所有所有的区域
(4) 从地址最小的区开始找，存在的区之间的缝隙是否可以， 如果没有就从最后一个malloc区到结束地址分出一个来
(5) 注册到红黑树中
(6) __vmalloc_area_node: 分配物理内存，计算包含多少页面，对每一个页面调用alloc_page
(7) 建立页面映射, 填充表项
```

##### 虚拟地址

```
查找VMA: find_vma 要么存在一个addr正好在VMA中，没有则返回一个VMA结束地址大于addr的
(1) 会现现在vmacache[4] 最近访问数组中找，没有再到红黑树中找

插入VMA：insert_vm_struct

合并VMA: vma_merge 将新的VMA与附近的VMA合并
```

+ malloc

```
brk:
	1. 计算新brk值
	2. 查找当前的start_addr是否与已有区域重合
```



 
