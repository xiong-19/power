llm：针对大模型的推理过程的优化
	1. 推理由：prompt输入生成与解码构成。
	2. 工作包含并行推理优化，单模型推理过程优化，多实例模型调度管理优化
	3. 多client的调度问题  (比较新，可做？？)
	
sosp	4.解决大模型需要GPU内存过高的问题

分布式系统：
	1.高效的fpga通信库
	2.分布式一致性的snapshot
	3.基于可编辑硬件的分布式锁
deep learning：
	1. 低精度数据的混合处理
	2. 收集系统数据，并再合适时机在线训练in-netword ml模型
	3. 并行训练计划生成


基于微内核的批量消息处理机制

NUMA中只读空间页面复制问题，
1. 对同一个可写数据页是不是不同核心，或者线程交替进行，
2. mpi程序对于同一node节点是不是聚拢访问，对于不同node节点会不聚拢访问（）
3.矩阵乘这种操作会就地就行吗（就地进行能否修改为新对象进行，动态修改二进制太复杂了）


watchdog: https://blog.csdn.net/ericstarmars/article/details/81750919
hangtask: https://linux.laoqinren.net/kernel/hungtask/

内存分层的双倍放置+非热页全放最快内存区
			|-----》没有做高频页处理	

参数形式的配置+启发式动态调整（大统一的内存分成策略，集各家之长）

预执行一次以回去不同执行对应的内存的访问频率（插桩如kprobe类似的方式动态分析）（对于只读的执行很有用感觉）

用户空间的并发错误检测工具。


用户空间中断：完成mpi通信？或者锁同步？


死锁调试分析工具。
